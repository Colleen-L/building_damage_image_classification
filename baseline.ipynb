{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a88babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "0.24.1\n",
      "2.3.5\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Pillow = PIL = Python library for image processing\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "# configs\n",
    "TRAIN_DIR = \"./data/train\"\n",
    "TEST_DIR =\"./data/test\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH = 32\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb686411",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "# parses labels from train filenames into ID and label\n",
    "def parse_train_files(train_dir):\n",
    "  files = glob(os.path.join(train_dir, \"*.png\"))\n",
    "  rows=[]\n",
    "  # HvD — Heavy Damage\n",
    "  # MiD — Minor Damage\n",
    "  # MoD — Moderate Damage\n",
    "  # UD — Undamaged\n",
    "  label_map = {\"HvD\":0,\"MiD\":1,\"MoD\":2,\"UD\":3}\n",
    "  for file in files:\n",
    "    name = os.path.basename(file)\n",
    "    id_part, label_part = name.split(\"_\")\n",
    "    label = label_map[label_part.replace(\".png\",\"\")]\n",
    "    rows.append((file,label))\n",
    "  \n",
    "  return pd.DataFrame(rows, columns = [\"path\", \"label\"])\n",
    "\n",
    "# batch loader\n",
    "def build_batch_tensor(batch, transform):\n",
    "  import io\n",
    "  images, labels = [], []\n",
    "  for path, label in batch:\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    # resize first\n",
    "    img = T.Resize((224, 224))(img)\n",
    "    # random flip if training\n",
    "    if isinstance(transform.transforms[1], T.RandomHorizontalFlip):\n",
    "      img = T.RandomHorizontalFlip()(img)\n",
    "    # convert PIL image to bytes and then to tensor\n",
    "    img_bytes = io.BytesIO()\n",
    "    img.save(img_bytes, format='PPM')\n",
    "    img_bytes.seek(0)\n",
    "    # read PPM format directly and convert to tensor\n",
    "    img_tensor = torch.frombuffer(img.tobytes(), dtype=torch.uint8).float() / 255.0\n",
    "    img_tensor = img_tensor.reshape(224, 224, 3).permute(2, 0, 1)\n",
    "    # apply normalization\n",
    "    img_tensor = T.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225])(img_tensor)\n",
    "    images.append(img_tensor)\n",
    "    labels.append(label)\n",
    "  return torch.stack(images), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b54239",
   "metadata": {},
   "source": [
    "## PREPARING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc8f3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_train_files(TRAIN_DIR)\n",
    "\n",
    "# stratified split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df.label, random_state=42)\n",
    "\n",
    "# training transformation\n",
    "train_transform = T.Compose([\n",
    "  T.Resize((224, 224)),\n",
    "  T.RandomHorizontalFlip(),\n",
    "  T.ToTensor(),\n",
    "  T.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225])\n",
    "])\n",
    "# validation transformation\n",
    "val_transform = T.Compose([\n",
    "  T.Resize((224, 224)),\n",
    "  T.ToTensor(),\n",
    "  T.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225])\n",
    "])\n",
    "\n",
    "# convert df to list of samples --> [(path, label), ...]\n",
    "train_samples = train_df.values.tolist()\n",
    "val_samples = val_df.values.tolist()\n",
    "\n",
    "# load training data\n",
    "train_loader = DataLoader(\n",
    "  train_samples,\n",
    "  batch_size=BATCH,\n",
    "  shuffle=True,\n",
    "  num_workers=0,\n",
    "  collate_fn=lambda b: build_batch_tensor(b, train_transform)\n",
    ")\n",
    "\n",
    "# load validation data\n",
    "val_loader = DataLoader(\n",
    "  val_samples,\n",
    "  batch_size=BATCH,\n",
    "  shuffle=False,\n",
    "  num_workers=0,\n",
    "  collate_fn=lambda b: build_batch_tensor(b, val_transform)\n",
    ")\n",
    "\n",
    "# create model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for p in model.parameters():\n",
    "  p.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "lossfn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6ec35",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96e90951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m8/81ptgb3x7j755glt7xp0jptc0000gn/T/ipykernel_23781/3754787080.py:36: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:1587.)\n",
      "  img_tensor = torch.frombuffer(img.tobytes(), dtype=torch.uint8).float() / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val acc 0.6147\n",
      "epoch 1 val acc 0.6365\n",
      "epoch 1 val acc 0.6365\n",
      "epoch 2 val acc 0.6486\n",
      "epoch 2 val acc 0.6486\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(3):\n",
    "  model.train()\n",
    "\n",
    "  for xb, yb in train_loader:\n",
    "    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "    preds = model(xb)\n",
    "    loss = lossfn(preds, yb)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "  \n",
    "  # validation\n",
    "  model.eval()\n",
    "  correct, total = 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for xb, yb in val_loader:\n",
    "          xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "          out = model(xb).argmax(dim=1)\n",
    "          correct += (out == yb).sum().item()\n",
    "          total += yb.size(0)\n",
    "\n",
    "  print(f\"epoch {epoch} val acc {correct / total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9148e7",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f4166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission_day1.csv\n"
     ]
    }
   ],
   "source": [
    "# predicting test set\n",
    "test_files = sorted(os.listdir(TEST_DIR), key=lambda x: int(x.split(\".\")[0]))\n",
    "rows = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for fn in test_files:\n",
    "    img = Image.open(os.path.join(TEST_DIR, fn)).convert(\"RGB\")\n",
    "    # Manual preprocessing: resize -> convert to tensor -> normalize (avoid torchvision.ToTensor)\n",
    "    img = T.Resize((224, 224))(img)\n",
    "    # Convert raw bytes to tensor (RGB)\n",
    "    raw = img.tobytes()\n",
    "    img_tensor = torch.frombuffer(raw, dtype=torch.uint8).float() / 255.0\n",
    "    img_tensor = img_tensor.reshape(224, 224, 3).permute(2, 0, 1)\n",
    "    img_tensor = T.Normalize(mean=[.485, .456, .406], std=[.229, .224, .225])(img_tensor)\n",
    "    x = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "    p = model(x).argmax(dim=1).item()\n",
    "    rows.append((fn, int(p)))\n",
    "\n",
    "pd.DataFrame(rows, columns=[\"ID\", \"Label\"]).to_csv(\"CL_first_submission.csv\", index=False)\n",
    "print(\"Wrote CL_first_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4e973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vip25_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
